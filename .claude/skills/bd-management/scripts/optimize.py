#!/usr/bin/env python3
"""
Beads Workflow Optimization Script
Optimizes task execution order and parallel processing
"""

import json
import sys
import os
from pathlib import Path
from typing import Dict, List, Set

def load_analysis_data():
    """Load workflow analysis data"""
    analysis_file = Path('.beads') / 'workflow_analysis.json'
    if not analysis_file.exists():
        print("âŒ No workflow analysis data found. Run 'scripts/analyze.py' first.")
        sys.exit(1)

    with open(analysis_file, 'r') as f:
        return json.load(f)

def optimize_workflow(analysis: Dict) -> Dict:
    """Optimize workflow based on analysis results"""
    optimized = {
        'parallel_groups': [],
        'execution_order': [],
        'recommendations': []
    }

    # Create parallel execution groups
    parallel_groups = []
    remaining_issues = analysis['ready_issues'].copy()

    while remaining_issues:
        current_group = []
        issues_to_remove = []

        for issue in remaining_issues:
            issue_id = issue.get('id')
            # Check if this issue depends on any issue in current group
            can_add = True
            for other_issue in current_group:
                other_id = other_issue.get('id')
                # Check dependencies (simplified - in real implementation would check full dependency map)
                can_add = can_add and True  # Placeholder for dependency checking

            if can_add:
                current_group.append(issue)
                issues_to_remove.append(issue)

        if current_group:
            parallel_groups.append(current_group)
            for issue in issues_to_remove:
                remaining_issues.remove(issue)
        else:
            break

    optimized['parallel_groups'] = parallel_groups

    # Create execution order
    execution_order = []
    for group in parallel_groups:
        execution_order.extend(group)
    optimized['execution_order'] = execution_order

    # Generate recommendations
    recommendations = []

    if analysis['blocked_count'] > 0:
        recommendations.append(f"âš ï¸  Address {analysis['blocked_count']} blocked issues to unlock parallel execution")

    if len(parallel_groups) > 1:
        recommendations.append(f"ğŸš€ {len(parallel_groups)} parallel execution groups available")

    if analysis['ready_count'] > 0:
        recommendations.append(f"âœ… {analysis['ready_count']} tasks ready for immediate execution")

    optimized['recommendations'] = recommendations

    return optimized

def main():
    """Main optimization function"""
    print("ğŸ”§ Optimizing Beads workflow...")

    try:
        analysis = load_analysis_data()
        optimized = optimize_workflow(analysis)

        print(f"\nğŸ“Š Optimization Results:")
        print(f"Parallel groups: {len(optimized['parallel_groups'])}")
        print(f"Total executable tasks: {len(optimized['execution_order'])}")

        if optimized['recommendations']:
            print(f"\nğŸ’¡ Recommendations:")
            for rec in optimized['recommendations']:
                print(f"  - {rec}")

        # Save optimization results
        output_file = Path('.beads') / 'workflow_optimization.json'
        with open(output_file, 'w') as f:
            json.dump(optimized, f, indent=2)

        print(f"\nğŸ“ Optimization saved to: {output_file}")

    except Exception as e:
        print(f"âŒ Optimization failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()